[TOC]

## 29 | 堆的应用：如何快速获取到 Top 10 最热门的搜索关键词？

-   思考：
    -   假设，**现在我们有一个包含 10 亿个搜索关键词的日志文件，如何快速获取到热门榜 Top 10 的搜索关键词呢？**

### 堆的应用一：优先级队列

-   优先级队列，顾名思义，它首先应该是一个队列。
    -   我们前面讲过，队列最大的特性就是先进先出。
    -   不过，在优先级队列中，数据的出队顺序不是先进先出，而是按照优先级来，**优先级最高的，最先出队。**
-   如何实现一个优先级队列呢？
    -   方法有很多，但是用堆来实现是最直接、最高效的。
    -   一个堆就可以看作是一个优先级队列。
        -   往优先级队列中插入一个元素，就相当于往堆中插入一个元素。
        -   从优先级队列中取出优先级最高的元素，就相当于取出堆顶元素。
-   下面，我来举两个例子，来感受一下优先级队列具体是怎么来用的。

#### 1. 合并有序小文件

-   需求：
    -   假设，我们有 100 个小文件，每个文件大小是 100MB，每个文件中存储的都是有序字符串。
    -   我们希望将这些 100 个小文件合并成一个有序的大文件。
    -   这里，就会用到优先级队列。
-   思路
    -   整体思路有点像归并排序中的合并函数。
    -   我们从 100 个文件中，各取第一个字符串，放入**数组**中，然后比较大小，把最小的那个字符串放入合并后的大文件中，并从数组中删除。
-   思考
    -   这里，我们用数组这种数据结构，来存储从小文件中取出来的字符串。每次从数组中取最小字符串，都需要循环遍历整个数组，显然，不是很高效。**有没有更加高效的方法呢？**

-   优化思路
    -   这里就可以**用到优先级队列，也可以说是堆**。
    -   我们将从小文件中取出来的字符串放入到小顶堆中，那堆顶的元素，也就是优先级队列队首的元素，就是最小的字符串。
    -   我们将这个字符串放入到大文件中，并将其从堆中删除。
    -   然后，再从小文件中取出下一个字符串，放入堆中。
    -   循环这个过程，就可以将 100 个小文件中的数据依次放入到大文件中。
-   小结
    -   删除堆顶数据和往堆中插入数据的时间复杂度都是 O(logn)，n 表示堆中的数据个数，这里就是 100。
    -   是不是比原来用数组存储高效了很多呢？

#### 2. 高性能定时器

-   需求
    -   假设，我们有一个定时器，定时器中维护了很多定时任务，每个任务都设定了一个要触发执行的时间点。
-   实现思路
    -   定时器每过一个很小的单位时间（如 1 秒），就扫描一遍任务，看是否有任务到达设定的执行时间。
    -   如果到达了，就拿出来执行。
    -   ![img](https://static001.geekbang.org/resource/image/b0/e7/b04656d27fd0ba112a38a28c892069e7.jpg)
-   思考
    -   这样，每过 1 秒，就扫描一遍任务列表的做法比较低效，主要原因有两点：
        1.  任务的约定执行时间离当前可能还要很久，这样，前面很多次扫描，其实都是徒劳。
        2.  每次都要扫描整个任务列表，如果任务列表很大的话，势必会比较耗时。
-   优化思路
    -   针对这些问题，我们就可以用优先级队列来解决。
    -   我们按照任务设定的执行时间，**将这些任务存储在优先级队列中，队列首部（也就是小顶堆的堆顶）存储的是最先执行的任务。**
    -   这样，定时器就不需要每隔 1 秒，就扫描一遍任务列表了。**它拿队首任务的执行时间点，与当前时间点相减，得到一个时间间隔 T。**
    -   **这个时间间隔 T 就是，从当前时间开始，需要等待多久，才会有第一个任务需要被执行。**这样，定时器就可以设定在 T 秒后，再来执行任务。从当前时间点到 （T-1）秒，这段时间里，定时器都不需要作任何事情。
    -   当 T 秒时间过去后，定时器取优先级队列中队首的任务执行。然后，再计算新的队首任务的执行时间点与当前时间点的差值 ，把这个值作为定时器执行下一个任务需要等待的时间。
    -   这样，定时器就不用每间隔 1 秒就轮询一次，也不用遍历整个任务列表，性能也就提高了。

### 堆的应用二：利用堆求 Top K

-   需求
    -   今天，我们来看下堆的另外一个非常重要的应用场景，那就是“求 Top K 问题”
    -   我把这个问题抽象成两类：
        1.  针对静态数据集合，
            -   也就是说数据集合事先确定，不会再变。
        2.  针对动态数据集合
            -   也就是说数据集合事先不确定，有数据动态地加入到集合中。
-   实现思路
    -   针对**静态数据**，如何在一个包含 n 个数据的数组中，查找前 K 大数据呢？
        -   我们可以**维护一个大小为 K 的小顶堆** ，顺序遍历数组，从数组中取出数据与堆顶元素比较。
        -   如果比堆顶元素大，我们就把堆顶元素删除，并且将这个元素插入到堆中。
        -   如果比堆顶元素小，则不做处理，继续遍历数组。
        -   这样，等数组中的数据遍历完之后，堆中的数据就是前 K 大数据了。
        -   遍历数组需要 O(n) 的时间复杂度，一次堆化操作需要 O(logK)的时间复杂度，所以，**最坏情况下，n个元素都入堆一次，时间复杂度就是 O(nlogK)。**
    -   针对动态数据，求得 Top K 就是实时 Top K。怎么理解？
        -   一个数据集合中的两个操作
            -   添加数据
            -   询问当前的前 K 大数据
        -   如果每次询问前 K 大数据，我们都基于当前数据重新计算的话，那时间复杂度就是 O(nlogK)，n 表示当前的数据大小。
        -   实际上，我们可以**维护一个 K 大小的小顶堆**，当有数据被添加到集合中时，我们就拿它与堆顶的元素对比。
        -   如果比堆顶元素大，我们就把堆顶元素删除，并且，将这个元素插入到堆中。
        -   如果比堆顶元素小，则不做处理。
        -   这样，无论任何时间需要查询当前的前 K 大数据，我们都可以立刻返回给他。

### 堆的应用三：利用堆求中位数

-   需求
    -   如何求动态数据集合**中位数**。

-   背景概要

    -   中位数
        -   就是处在中间位置的那个数。
        -   如果数据个数是个**奇数**，把数据从小到大排列，那第 n/2 + 1 个数据就是中位数。
        -   如果数据个数是个**偶数**，那处于中间位置的数据有两个，第 n/2 个和 第 n/2 + 1 个数据。这时，我们可以随意取一个作为中位数，
        -   ![img](https://static001.geekbang.org/resource/image/18/b6/1809157fdd804dd40a6a795ec30acbb6.jpg)

-   实现思路

    -   **静态数据集合**
        -   中位数是固定的，我们可以先排好序，第 n/2 个数据就是中位数。
        -   每次询问中位数的时候，我们直接返回这个固定的值就好了。
        -   尽管排序的代价比较大，但，边际成本会很小。
    -   **动态数据集合**
        -   中位数在不停的变动，如果再用先排序的方法，每次询问中位数的时候，都要先进行排序，那效率就不高了。

-   优化思路

    -   **借助堆这种数据结构，我们不用排序，就可以非常高效地实现求中位数操作。**我们来看看，它是如何做到的？
        -   我们维护两个堆 
            -   一个**大顶堆**
                -   存储**前半部分**数据
            -   一个**小顶堆**
                -   存储**后半部分**数据
        -   小顶堆中的数据都大于大顶堆中的数据。
        -   假设，如果有 n 个数据
            -   n 是偶数，我们从小到大排序。
                -   那前 n/2 个数据存储在大顶堆中，后 n/2 个数据存储在小顶堆中。
                -   这样，大顶堆中的堆顶元素，就是我们要找的中位数。
            -   n 是奇数，情况是类似的。
                -   大顶堆就存储 n/2 + 1 个数据，小顶堆中就存储 n/2 个数据。
            -   ![img](https://static001.geekbang.org/resource/image/08/99/08c29d3e014a4baf5f8148c2271e6099.jpg)
        -   当**新添加一个数据的时候**，我们如何调整两个堆 ，让大顶堆中的堆顶元素继续是中位数呢？
            -   如果新加入的数据小于等于大顶堆的堆顶元素，那我们就将这个数据插入到大顶堆。
            -   否则，我们就将这个新数据插入到小顶堆。
            -   这时，**就有可能出现，两个堆中的数据个数不符合前面约定的情况**（如果 n 是偶数，两个堆中的数据个数都是 n/2，如果 n 是奇数，大顶堆有 n/2 + 1 个数据，小顶堆有 n/2 个数据。）。
                -   这个时候，我们可以从一个堆中不停地将堆顶元素移动到另一个堆，通过这样调整，来让两个堆中的数据满足上面的约定。
                -   ![img](https://static001.geekbang.org/resource/image/ae/b1/aee4dcaf9d34111870a1d66a6e109fb1.jpg)
        -   于是，我们就可以利用两个堆，一个大顶堆，一个小顶堆，实现在动态数据集合中求中位数的操作。
        -   时间复杂度
            -   插入数据因为需要涉及堆化，所以，时间复杂度就变成了 **O(logn)**，
            -   但是，求中位数我们只需要返回大顶堆的堆顶元素就可以了，所以，时间复杂度是 **O(1)**。

-   扩展

    -   利用两个堆不仅可以快速求出中位数，还可以快速**求出其他百分位的数据**。原理类似。

    -   **“如何快速求接口的 99% 响应时间？”**

    -   什么是“99% 响应时间”

        -   **中位数的概念就是将数据从小到大排列，处于中间位置，就叫中位数，这个数据会大于等于前面 50% 的数据。**
        -   99 百分位数的概念可以类比中位数，如果将一组数据从小到大排列，**这个 99 百分位数就是大于前面 99% 数据的那个数据。**
        -   例：假设有 100 个数据，分别是 1， 2，3，……， 100， 那 99 百分位数就是 99，因为小于等于 99 的数占总个数的 99%。
        -   ![img](https://static001.geekbang.org/resource/image/bb/2d/bbb043d369eeef1bb7feadd28c6ea32d.jpg)

        -   小结
            -   如果有 n 个数据，将数据从小到大排列后，99 百分位数大约就是第 `n*99%` 个数据，同类，80 百分位数大约就是第 `n*80%`个数据。

    -   如何求 99% 响应时间

        -   我们**维护两个堆**，一个大顶堆，一个小顶堆。
            -   假设当前总数据的个数是 n，大顶堆中保存 `n*99%` 个数据，小顶堆中保存 `n*1%` 个数据。
            -   那大顶堆的堆顶的数据就是我们要找的 99% 响应时间。
        -   每次**插入一个数据的时候**，我们要判断这个数据跟大顶堆和小顶堆堆顶数据的大小关系，然后决定插入到哪个堆中。
            -   如果这个新插入的数据比大顶堆的堆顶数据小，那就插入大顶堆。
            -   如果这个新插入的数据比小顶堆的堆顶数据大，那就插入小顶堆。
        -   为保持大顶堆中数据占 99%，小顶堆中数据占 1%，**每次新插入数据之后，我们都要重新计算，这个时候大顶堆和小顶堆中的数据个数，是否还符合 99:1 的比例。**如果不符合，我们就将一个堆中的数据移动到另一个堆，直到满足这个比例。移到的方法类似前面求中位数的方法。

    -   时间复杂度

        -   每次插入数据，可能会涉及几个数据的堆化操作，所以，时间复杂度是 O(logn)。
        -   每次求 99% 响应时间的时候，直接返回大顶堆中的堆顶数据即可，时间复杂度是 O(1)。

### 解答开篇

-   假设，现在我们有一个包含 10 亿个搜索关键词的日志文件，**如何快速获取到 Top 10 最热门的搜索关键词呢?**
-   处理场景
    -   我们将处理场景限定为单机，可使用内存为 1GB。
-   实现
    -   第一，因为搜索关键词，有很多可能都是重复的，所以，我们首先要**统计出每个搜索关键词出现的频率。**
        -   假设，我们选用散列表。我们就顺序扫描这 10 亿个关键词。当扫描到某个关键词时，我们去散列表中查询。
            -   如果存在，我们就将对应的次数加一。
            -   如果不存在，我们就将它插入到散列表，并记录次数为 1。
        -   以此类推，等遍历完这 10 亿个搜索关键词后，散列表中就存储了不重复的搜索关键词以及出现的次数。
    -   第二，再根据前面讲的用堆求 Top K 的方法，建立一个大小为 10 的小顶堆。
        -   遍历散列表，依次取出每个搜索关键词及对应出现的次数，然后与堆顶的搜索关键词对比。
            -   如果次数比堆顶搜索关键词的次数多，那就删除堆顶的关键词，将这出现次数更多的关键词加入到堆中。
            -   以些类推，当遍历完整个散列表中的搜索关键词后，堆中的搜索关键词就是出现次数最多的 Top 10 搜索关键词了。
-   思考
    -   上面的解决思路其实存在漏洞。
    -   10 亿的关键词还是很多的。我们假设 10 亿条搜索关键词中不重复的有 1 亿条，如果每个搜索关键词的平均长度是 50 个字节，那存储 1 亿个关键词起码需要 5GB 的内存空间，而散列表因为要避免频繁冲突，不会选择太大的装载因子，所以，内存消耗的内存空间就更多了。
    -   我们无法将所有搜索关键词加入到内存中。这个时候该怎么办呢?
-   优化思路
    -   我们在哈希算法那一节讲过，相同数据经过哈希算法得到的哈希值是一样的。我们可以根据哈希算法这个特点，将 10 亿条搜索关键词通过哈希算法分片到 10 个文件中。
        -   我们遍历这 10 亿个关键词，**并且通过某个哈希算法对其求哈希值，然后，哈希值同 10 取模，**得到的结果就是这个搜索关键词应该被分到的文件编号。
    -   对这 10 亿关键词分片后，每个文件都只有 1 亿关键词，去除重复的，可以就只有 1000 万个，每个关键词平均 50 个字节，所以总的大小就是 500MB。1GB 的内存完全可以放得下。
    -   我们针对每个文件，利用散列表和堆，分别求出 Top10，然后，把这 10 个 Top 10 放在一块，取这 100 关键词中，出现次数最多的 10 个关键词，这就是 10 亿数据中的 Top 10 最频繁的搜索关键词了。

### 内容小结

-   今天，我们主要讲了堆的几个重要应用：
    -   优先级队列
    -   求 Top K 问题
    -   求中位数问题
-   优先级队列
    -   它是一种特殊的队列，优先级高的数据先出队，而不再像普通的队列那样，先进先出。实际上，堆就可以看作是优先级队列，只是称谓不一样罢了。
-   求 Top K
    -   静态数据
    -   动态数据
-   求中位数
    -   它实际上还有很多变形。但，处理思路都是一样的，即利用两个堆，一个大顶堆，一个小顶堆。
    -   随着数据的动态添加，动态调整两个堆中的数据，最后大顶堆的堆顶元素就是要求的数据。

### 课后思考

1.  一个访问量非常大的新闻网站，我们希望将点击量排名 Top 10 新闻摘要，滚动显示在网站首页上，并且，每隔 1 小时更新一下。如果你是负责开发这个功能的工程师，你会如何实现？

#### 精选一

1.  我的思路是这样的：
    1.  对每篇新闻摘要计算一个 hashcode，并建立摘要与 hashcode 的关联关系，使用 map 存储以 hashcode 为 key ，新闻摘要为值。
    2.  按每小时一个文件的方式记录下被点击的摘要的 hashcode。
    3.  当一个小结束后，上一个小时的文件被关闭，开始计算上一个小时的点击 Top 10。
    4.  将 hashcode 分片到多个文件中，通过对 hashcode 取模运算，即可将相同的 hashcode 分片到相同的文件中。
    5.  针对每个文件取 Top 10 的 hashcode，使用 `Map<hashcode, int>` 的方式，统计出所有摘要点击次数，然后，再使用小顶堆（大小为 10）计算 Top 10。
    6.  再针对所有分片计算一个总的 Top 10，最后合并的逻辑也是使用小顶堆，计算 Top 10。
    7.  如果仅展示前一小时的 Top 10，计算结束。
    8.  如果需要展示全天，需要与上一次的计算按 hashcode 进行合并，然后，再在这个合并的数据中取 Top 10。
    9.  在展示时，将计算得到的 Top 10 的 hashcode转化为新闻摘要，显示即可。



