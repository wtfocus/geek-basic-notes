[toc]

## 06 | 链表（上）：如何实现LRU缓存淘汰算法?

0.  开篇问题：**如何用链表来实现 LRU 缓存淘汰策略呢？**

1.  数组 vs 链表 -- **存储结构**
    -   数组，**连续的内存空间**
    -   链表，通过指针将一组**零散的内存块**串联起来
    -   ![img](imgs/d5d5bee4be28326ba3c28373808a62cd.jpg)

2.  三种最常见的链表结构： **单链表、双向链表、循环链表**。

3.  **单链表**
    -   每个结点包含：
        -   数据
        -   下一个结点的地址（**后继指针 next**）
    -   内存分布
        -   ![img](imgs/b93e7ade9bb927baad1348d9a806ddeb.jpg)
    -   头结点：链表的**基地址**
    -   尾结点：**空地址 Null**
    -   插入、删除：时间复杂度 **O(1)**
        -   ![img](imgs/452e943788bdeea462d364389bd08a17.jpg)
    -   随机访问：时间复杂度是 **O(n)**
    
4.  **循环链表**
    -   **是一种特殊的单链表**，循环链表的尾结点指针指向链表的头结点。
        -   ![img](imgs/86cb7dc331ea958b0a108b911f38d155.jpg)

5.  **双向链表**

    -   **它支持两个方向，每个结点不止有一个后继指针 next 指向后面的结点，还有一个前驱指针 prev 指向前面的结点。**
        -   ![img](imgs/cbc8ab20276e2f9312030c313a9ef70b.jpg)

    -   双向链表要比单链表**占用更多的内存空间**。
    -   支持**双向遍历**，这样也带来了双向链表操作的灵活性，可以支持 **O(1)** 时间复杂度的情况下找到前驱结点。

	-  **删除操作**

        + 两种情况：
            + 删除结点中“值等于某个给定值”的结点。
            + 删除给定指针指向的结点。
        + **第一种情况**，单纯删除操作的时间复杂度是 **O(1)**，遍历查找的时间复杂度是 **O(n)**。
        + **第二种情况**，要删除结点 q ，需要知道其前驱结点。
            + **单向链表**，并不能直接获取前驱结点。所以，为了找前驱结点，我们还是需要从头结点开始遍历链表，直到 p->next=q，说明 p 是 q 的前驱结点。这里时间复杂度是 **O(n)**。
            + **双向链表**，因为双向链表中结点已经保存了前驱结点的指针，不需要像单向链表那样遍历。这里时间复杂度是 **O(1)**。
    + 案例：`LinkedHashMap` -- Java
    + 设计思想：**空间换时间**
    
6.  **双向循环链表**，循环链表和双向链表整合。

    -   ![img](imgs/d1665043b283ecdf79b157cfc9e5ed91.jpg)

7.  链表 vs 数组 -- **性能**
    -   时间复杂度
        -   ![img](imgs/4f63e92598ec2551069a0eef69db7168.jpg)

    + 其他
        + 数组**简单易用**，在实现上使用的是**连续的内存空间**，可以**借助 CPU 缓存机制**，预读数组中的数据，所以**访问效率更高**。而**链表在内存中并不是连续存储**，所以对 CPU 缓存并不友好，没办法有效预读。
        + 数组的缺点是**大小固定**，占用整块**连续的**内存空间。如果，数组大小不够用了，还需要进行**扩容**，非常耗时。而**链表本身没有大小的限制，天然地支持动态扩容**，这也是它们最大的区别。
        + 链表中每个结点都需要消耗额外的存储空间去存储一份指向下一个结点的指针，所以**内存消耗**会翻倍。
        + 而且对链表进行频繁的插入、删除操作，还需要导致**频繁的内存申请和释放**，容易**造成内存碎片**。如果是 Java 语言，就可能会导致频繁的 GC(Garbage Collection,垃圾回收)。
### 解答开篇

1.  **如何基于链表实现 LRU 缓存淘汰算法？**

    - 思路：
         - 我们维护一个有序单链表。
         - 越靠近链表尾部的结点是越早之前访问的。
         - 当有一个新的数据被访问时，我们从链表头开始顺序遍历链表。
    - 各种情况：

         1. 如果数据**已经缓存在链表中**
             -   我们遍历得到这个数据对应的结点，并将其从原来的位置删除，然后再插入到链表头部。
         2. 如果数据**没有**缓存链表中，又分两种情况：
             - 如果此时**缓存未满**，则将此结点直接插入到链表的头部。
             - 如果此时**缓存已满**，则链表尾结点删除，将新的数据结点插入到链表的头部。
    - 时间复杂度：
         - 因为不管缓存有没有满，我们都需要遍历一次链表，所以，时间复杂度是 **O(n)**。
    - 优化：
         - **散列表（Hash table）** ，将缓存访问的时间复杂度降到 O(1)。

### 课后思考

- 判断一个字符串是否是回文字符串。

### 精选留言

1.  #Rain

    >   Re Ydyhm:
    >
    >   “数组简单易用，在实现上使用的是连续的内存空间，可以借助 CPU 的缓存机制，预读数组中的数据，所以访问效率更高。而链表在内存中并不是连续存储，所以对 CPU 缓存不友好，没办法有效预读。” 
    >
    >   这里的CPU缓存机制指的是什么？为什么就数组更好了？
    >
    >   
    >
    >   \----
    >
    >   
    >
    >   我没有百度也没有Google。之前开发时遇到过，我斗胆说下。
    >
    >   CPU在从内存读取数据的时候，会先把读取到的数据加载到CPU的缓存中。
    >
    >   而CPU每次从内存读取数据并不是只读取那个特定要访问的地址，而是读取一个数据块(这个大小我不太确定。。)并保存到CPU缓存中，然后下次访问内存数据的时候就会先从CPU缓存开始查找，
    >
    >   如果找到就不需要再从内存中取。这样就实现了比内存访问速度更快的机制，也就是CPU缓存存在的意义:为了弥补内存访问速度过慢与CPU执行速度快之间的差异而引入。
    >
    >   
    >
    >   对于数组来说，存储空间是连续的，所以在加载某个下标的时候可以把以后的几个下标元素也加载到CPU缓存这样执行速度会快于存储空间不连续的链表存储。
    >
    >   
    >
    >   大牛请指正哈！

2.  #Liam

    >   1 快慢指针定位中间节点
    >
    >   2 从中间节点对后半部分逆序
    >
    >   3 前后半部分比较，判断是否为回文
    >
    >   4 后半部分逆序复原
    >
    >   
    >
    >   时间复杂度On, 空间复杂度O1
    >   把LRU和回文都实现了一遍~~
    >
    >   如果是双向链表，时间效率更高，看了下LinkedList，底层也是用双向链表实现