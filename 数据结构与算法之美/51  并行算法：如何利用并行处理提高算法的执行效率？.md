[TOC]

## 51 | 并行算法：如何利用并行处理提高算法的执行效率？

- **当算法无法再继续优化的情况下，我们该如何来进一步提高执行效率呢？**
- **如何借助并行计算的处理思想对算法进行改造？**

### 并行排序

- 假设我们要为 8GB 数据进行排序，并且，我们机器的内存可以一次容纳这么多数据。
- 从理论上，这个排序问题，已经很难从算法层面优化了。而利用并行处理的思想，我们可以很轻松地将这个执行效率提高很多倍。
- 实现思路有下面两种：

#### 第一种，是对归并排序并行化处理

- 将 8GB 的数据划分成 16 个小的数据集合，每个集合 500MB 数据。
- 我们用 16 个线程，并行地对这 16 个 500MB 的数据集合进行排序。
- 这 16 个小集合分别排序完成后，再将 16 个有序集合合并。

#### 第二种，是对快速排序并行化处理

- 先扫描一遍数据，找到数据所处的范围区间。
- 把这个区间从小到大划分成 16 个小区间。
- 将这 8GB 数据划分到对应的区间中。
- 针对 16 个小区间的数据，我们启动 16 个线程，并行地进行排序。
- 等到 16 个线程都执行结束后，得到的数据就是有序数据了。

#### 总结

- 相同点：
    - 这两种思路，都是利用分治思想，对数据进行分片，然后并行处理。
- 区间：
    - 第一种处理思路是，先随意地对数据分片，排序后再合并。
    - 第二种处理思路是，先对数据按大小划分区间，然后再排序，排完序就不需要再处理了。

### 并行查找

- 散列表是一种非常适合快速查找的数据结构。
- 我们在给动态数据构建索引，在数据不断加入的时候，散列表的装载因子就会越来越大。为了保证散列表的性能不下降，我们就需要对散列表进行**动态扩容**。
- 对如此大的散列表进行动态批扩容，**一方面比较耗时，另一方面比较消耗内存。**
    - 如果我们给一个 2GB 大小的散列表进行扩容，扩展到原来的 1.5 倍，也就是 3GB 大小。
    - 这个时候，实际存储在散列表中的数据只有不到 2GB，所以内存的利用率只有原来的 60%，有 1GB 的内存是空闲的。
- 实际上，**我们可以将数据分割成 k 份（如 16），每份中的数据只有原来的 1/k，然后我们针对这 k 个数据集合分别构建散列表。**
    - 这样，散列表的维护成本也就变低了。
    - 当某个小散列表的装载因子过大的时候，我们可以单独对这个散列表进行扩容，而其他散列表不需要扩容。
- 还是刚才的例子，
    - 2GB 的数据，放到 16 个散列表中，每个散列表中的数据大约 150MB。
    - 当某个散列表需要扩容时，我们只需要额外增加 150*0.5=75MB 的内存（假设，还是扩容原来的 1.5 倍）。
    - 不管从扩容的执行效率还是内存利用率上，这种多个小散列表的处理方法，都要比大散列表高效。
- 当要查找某个数据时，我们只需要通过 16 个线程，并行地在这个 16 个散列表中查找数据。这样的查找性能，比起一个大散列表的做法，并不会下降，反倒可能提高。
- 当往散列中添加数据的时候，我们可以选择将这个新的数据放入装载因子最小的那个散列表中，这样也有助于减少散列冲突。

####并行字符串匹配

- 在文本中查找某个关键词这样一个功能，可以通过字符串匹配算法来实现。我们之前学习的字符串匹配算法有 **KMP、BM、RK、BF** 等。
- 当在一个**不是很长的文本中查找关键词**的时候，
    - 这些字符串匹配算法，都可以表现得非常高效。
- 但，如果我们**处理的是超级大的文本**，那处理时间可能就会变得很长，那有没有办法加快匹配速度呢？
    - 我们可以**把大的文本，分割成 k 个小文本。**
    - 假设 k 是 16，我们就启动 16 个线程，并行地在这 16 个小文本中查找关键词，这样整个查找性能就提高了 16 倍。
    - 16 倍的效率提升，从真实的软件开发来说，这显然是一个非常可观的优化。
    - 不过，这里还有一个细节要处理。
        - 那就是原本包含在大文本中的关键词，被一分为二，分割到两个小文本中，这就会导致大文本中包含这个关键词，但在这 16 个小文本中查找不到它。这个问题也不难解决，我们只需要对这种特殊情况，做一些特殊处理就可以了。
        - 假设关键词长度是 m 。我们每个小文本的结尾和开始各取 m 个字符串。前一个小文本的末尾的 m 个字符和后一个小文本的开关的 m 个字符，组成一个长度是 2m 的字符串。我们再拿关键词，在这个长度是 2m 的字符串中重新查找一遍，就可以解决以上的漏洞了。

#### 并行搜索

- 对于广度优先搜索算法，我们可以将其改造成并行算法。
- 广度优先搜索是一种逐层搜索的搜索策略。基于当前这一层顶点，我们可以启动多个线程，并行地搜索下一层的顶点。在代码实现方法，原来广度优先搜索的代码实现，是通过一个队列来记录已经遍历但还没有扩展的顶点。现在，经过改造后的并行广度优先搜索算法，我们需要利用两个队列来完成扩展顶点的工作。
    - 假设这两个队列分别是队列 A 和队列 B 。
    - 多线程并行处理队列 A 中的顶点，并将扩展得到顶点存储在队列 B。
    - 等队列 A 中的顶点都扩展完成后，队列 A 被清空，我们再并行地扩展队列 B 中的顶点，并将扩展出来的顶点存储在队列 A 。
    - 这样两个队列循环使用，就可以实现并行广度优先搜索算法。

### 总结引申

- 今天，我们通过 “并行算法” 这个话题，回顾了之前学过的一些算法。
- 我们通过一些例子，如并行排序、查找、搜索、字符串匹配，给你展示了并行处理的实现思路，**也就是对数据进行分片，对没有依赖关系的任务并行地执行。**
- 并行计算是一个工程上的实现思路，尽管跟算法关系不大，但是，在实际的软件开发中，它确定可以非常巧妙的提高程序的运行效率，是一种非常好用的性能优化手段。
- 特别是，**当要处理的数据规模达到一定程度后，我们无法通过继续优化算法，来提高执行效率的时候，我们就需要在实现的思路上做文章，利用更多的硬件资源，来加快执行的效率**。所以在很多超大规模的数据处理中，并行处理的思想，应用非常广泛。如 MapReduce 实际上就是一种并行计算框架。

### 课后思考

- 假设我们有 n 个任务，为了提高执行的效率，我们希望并行执行任务，但是各任务间又有一定的依赖关系，如何根据依赖关系找出可以并行执行的任务？

#### 精选 一

- 用一个有向图来存储任务间的依赖关系，然后用拓扑排序的思想来执行任务。
- 每次都找到入度为 0 的，放在队列里，启动线程池开始执行。
- 队列里的任务并行执行完毕，再次调用拓扑排序找到入席为 0 的人，放入队列，直到所有任务跑完。

